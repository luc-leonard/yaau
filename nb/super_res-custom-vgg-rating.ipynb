{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torch\n",
    "import time\n",
    "now = str(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/lleonard/Documents/datasets/danbooru/0/danbooru2020/')\n",
    "path_hr = path/'512px'\n",
    "path_lr = path/'96px'\n",
    "path_mr = path/'256px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = get_image_files(path_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,size=32,128\n",
    "arch = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_id(full_id):\n",
    "    return str(int(full_id) % 1000).zfill(4)\n",
    "\n",
    "def short_id_from_filename(filename):\n",
    "    return short_id(int(filename.name[:-4]))\n",
    "\n",
    "def get_y(x):\n",
    "    parent_folder = short_id_from_filename(x)\n",
    "    return path_hr / parent_folder / x.name\n",
    "\n",
    "def get_subset_images(start_folder, end_folder):\n",
    "    def f(path):\n",
    "        return [f for f in get_image_files(path) if short_id_from_filename(f) <=end_folder and short_id_from_filename(f) >= start_folder]\n",
    "    return f\n",
    "\n",
    "def get_dls(bs,size):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, ImageBlock),\n",
    "                   get_items=get_subset_images('0000','0001'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter(),\n",
    "                   item_tfms=Resize(size),\n",
    "                   batch_tfms=[*aug_transforms(max_zoom=2.), Normalize()])\n",
    "    dls = dblock.dataloaders(path_lr, bs=bs, path=path, item_tfms=Resize(size))         \n",
    "    dls.c = 3\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(bs,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.train.show_batch(max_n=4, figsize=(18,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor(dls.valid_ds[0][1]).float().permute(2,0,1)/255.\n",
    "t = torch.stack([t,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_matrix(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('./models/danbooru_vgg_rating_classifier.pth')\n",
    "vgg_m = data['model'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [i-1 for i,o in enumerate(vgg_m.children()) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target, reduction='mean'):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target,reduction=reduction)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out,reduction=reduction)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out),reduction=reduction)*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        if reduction=='none': \n",
    "            self.feat_losses = [f.mean(dim=[1,2,3]) for f in self.feat_losses[:4]] + [f.mean(dim=[1,2]) for f in self.feat_losses[4:]]\n",
    "        for n,l in zip(self.metric_names, self.feat_losses): setattr(self, n, l)\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, arch, loss_func=feat_loss, metrics=LossMetrics(feat_loss.metric_names),\n",
    "                     blur=True, norm_type=NormType.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9):\n",
    "    learn.fit_one_cycle(10, lrs, pct_start=pct_start, wd=wd)\n",
    "    learn.save(save_name + '_' + now)\n",
    "    learn.show_results(max_n=2, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_fit('danbooru_custom_classifier_1a', slice(lr*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(ds_idx=1, max_n=2, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('danbooru_custom_classifier_1b', slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(12,size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls = dls\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('danbooru_custom_classifier_1b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('danbooru_custom_classifier_2a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('danbooru_custom_classifier_2b', slice(1e-6,1e-4), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(ds_idx=1, max_n=2, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(1,size)\n",
    "loaded_learn = unet_learner(dls, arch, loss_func=feat_loss, metrics=LossMetrics(feat_loss.metric_names),\n",
    "                     blur=True, norm_type=NormType.Weight)\n",
    "dls = get_dls(1,size * 2)\n",
    "loaded_learn.dls = dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_learn.load('danbooru_custom_classifier_2b');\n",
    "loaded_learn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_learn.show_results(ds_idx=1, max_n=2, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import torchvision.transforms as T\n",
    "ratings = pd.read_csv('clean_0000.csv')\n",
    "image_id = ratings[ratings['rating'] == 's'].sample(1).values[0][0]\n",
    "\n",
    "id = short_id(image_id)\n",
    "\n",
    "image = PILImage.create(glob.glob(str(path_hr / id / str(image_id)) + '.*')[0])\n",
    "show_image(image)\n",
    "print(image.shape)\n",
    "\n",
    "part_size = 64\n",
    "w, h = image.size\n",
    "image = image.crop((w/2-(part_size / 2), h/2-(part_size / 2),w/2+(part_size / 2), h/2+(part_size / 2))).resize((512,512))\n",
    "\n",
    "#convert to fastai image type\n",
    "image = PILImage.create(np.array(image.convert('RGB')))\n",
    "\n",
    "show_image(image.resize((256,256), Image.LANCZOS))\n",
    "print(image.shape)\n",
    "\n",
    "\n",
    "img_hr,*_ = loaded_learn.model(ToTensor()(image).unsqueeze(0).float().cuda() / 255.)\n",
    "print(img_hr.shape)\n",
    "show_image(img_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model': loaded_learn.model}, './super_res.pth')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}